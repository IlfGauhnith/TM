{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "freIdhjgnLzQ"
      },
      "source": [
        "## Adaptando dataset ao Flair\n",
        "O Flair recebe o dataset dividido em train, test e dev para treinar o modelo. Portanto inicialmente tratarei o dataset para adequá-lo ao Flair.\n",
        "As células abaixo embaralham, dividem e salvam o dataset em arquivos txt.\n",
        "\n",
        "A implementação busca o dataset montando o Google Drive. Para mudar o caminho do arquivo em seu drive atualize a variável DATASET_GDRIVE_PATH."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iAoTKycgoXi-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZelmWLi7pl9Y",
        "outputId": "94653b04-4361-48a3-8612-38c7058919e8"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('./ner_dataset.csv', encoding='Latin-1')\n",
        "df = df.fillna(method='ffill') # Preenche as colunas NA com a informação da célula acima\n",
        "df = df.set_index('Sentence #', append=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iUhj7PlMf6Et"
      },
      "outputs": [],
      "source": [
        "# Embaralha o dataset mantendendo a estrutura das sentenças intactas. \n",
        "def shuffle_preserving_sentences(df):\n",
        "  sentence_groupby = df.groupby('Sentence #') # Agrupa por sentença\n",
        "\n",
        "  sentences_shuffled = list(sentence_groupby.groups.keys()) # Lista das chaves de cada grupo \n",
        "  random.shuffle(sentences_shuffled) # Embaralha as chaves\n",
        "\n",
        "  # Cria e preenche uma lista com os dataframes de cada sentença. \n",
        "  shuffled_dfs = []\n",
        "  for sentence_n in sentences_shuffled:\n",
        "    shuffled_dfs.append(sentence_groupby.get_group(sentence_n))\n",
        "\n",
        "  return shuffled_dfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NcGZrchpno49"
      },
      "outputs": [],
      "source": [
        "def write_sentences_to_file(groupby, file):\n",
        "  for _, group in groupby:\n",
        "    group.to_csv(file, index=False, header=False, sep=' ', encoding='Latin-1', lineterminator='\\n')\n",
        "    file.write('\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8TucbVespaz-"
      },
      "outputs": [],
      "source": [
        "def split_dataset(df, train_ratio, test_ratio):\n",
        "  sentences_dfs = shuffle_preserving_sentences(df)\n",
        "\n",
        "  total_size = len(sentences_dfs)\n",
        "  train_size = int(total_size * train_ratio)\n",
        "  test_size = int(total_size * test_ratio)\n",
        "\n",
        "  train_data = pd.concat(sentences_dfs[:train_size])\n",
        "  test_data = pd.concat(sentences_dfs[train_size:train_size + test_size])\n",
        "  dev_data = pd.concat(sentences_dfs[train_size + test_size:])\n",
        "\n",
        "  return train_data, test_data, dev_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_WJRziuwmySm"
      },
      "outputs": [],
      "source": [
        "train_ratio = 0.8\n",
        "test_ratio = 0.1\n",
        "train_df, test_df, dev_df = split_dataset(df, train_ratio, test_ratio)\n",
        "\n",
        "with open('./train.txt', 'w', encoding='Latin-1') as f:\n",
        "  train_df_groupby = train_df.groupby('Sentence #')\n",
        "  write_sentences_to_file(train_df_groupby, f)\n",
        "\n",
        "with open('./test.txt', 'w', encoding='Latin-1') as f:\n",
        "  test_df_groupby = test_df.groupby('Sentence #')\n",
        "  write_sentences_to_file(test_df_groupby, f)\n",
        "\n",
        "with open('./dev.txt', 'w', encoding='Latin-1') as f:\n",
        "  dev_df_groupby = dev_df.groupby('Sentence #')\n",
        "  write_sentences_to_file(dev_df_groupby, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oaGdQmSvWx9"
      },
      "source": [
        "## Carregando dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2Vrf0fyew5qG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flair in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.12.2)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\lucas\\appdata\\roaming\\python\\python39\\site-packages (from flair) (2.8.2)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (2.0.1)\n",
            "Requirement already satisfied: gensim>=3.8.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (4.3.1)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (4.65.0)\n",
            "Requirement already satisfied: segtok>=1.5.7 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (1.5.11)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (3.7.2)\n",
            "Requirement already satisfied: mpld3==0.3 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (1.3.0)\n",
            "Requirement already satisfied: sqlitedict>=1.6.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (2.1.0)\n",
            "Requirement already satisfied: deprecated>=1.2.4 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (1.2.14)\n",
            "Requirement already satisfied: hyperopt>=0.2.7 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (0.2.7)\n",
            "Requirement already satisfied: boto3 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (1.28.14)\n",
            "Requirement already satisfied: transformers[sentencepiece]>=4.18.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (4.31.0)\n",
            "Requirement already satisfied: bpemb>=0.3.2 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (0.3.4)\n",
            "Requirement already satisfied: regex in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (2023.6.3)\n",
            "Requirement already satisfied: tabulate in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (0.9.0)\n",
            "Requirement already satisfied: langdetect in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (1.0.9)\n",
            "Requirement already satisfied: lxml in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (4.9.3)\n",
            "Requirement already satisfied: ftfy in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (6.1.1)\n",
            "Requirement already satisfied: janome in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (0.5.0)\n",
            "Requirement already satisfied: gdown==4.4.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (4.4.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (0.16.4)\n",
            "Requirement already satisfied: conllu>=4.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (4.5.3)\n",
            "Requirement already satisfied: more-itertools in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (10.0.0)\n",
            "Requirement already satisfied: wikipedia-api in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (0.6.0)\n",
            "Requirement already satisfied: pptree in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (3.1)\n",
            "Requirement already satisfied: pytorch-revgrad in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (0.2.0)\n",
            "Requirement already satisfied: transformer-smaller-training-vocab>=0.2.1 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair) (0.2.4)\n",
            "Requirement already satisfied: filelock in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gdown==4.4.0->flair) (3.12.2)\n",
            "Requirement already satisfied: requests[socks] in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gdown==4.4.0->flair) (2.31.0)\n",
            "Requirement already satisfied: six in c:\\users\\lucas\\appdata\\roaming\\python\\python39\\site-packages (from gdown==4.4.0->flair) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gdown==4.4.0->flair) (4.12.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from bpemb>=0.3.2->flair) (1.25.1)\n",
            "Requirement already satisfied: sentencepiece in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from bpemb>=0.3.2->flair) (0.1.99)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from deprecated>=1.2.4->flair) (1.15.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gensim>=3.8.0->flair) (1.11.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gensim>=3.8.0->flair) (6.3.0)\n",
            "Requirement already satisfied: fsspec in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub>=0.10.0->flair) (2023.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub>=0.10.0->flair) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lucas\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.10.0->flair) (4.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\lucas\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.10.0->flair) (23.1)\n",
            "Requirement already satisfied: networkx>=2.2 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from hyperopt>=0.2.7->flair) (3.1)\n",
            "Requirement already satisfied: future in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from hyperopt>=0.2.7->flair) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from hyperopt>=0.2.7->flair) (2.2.1)\n",
            "Requirement already satisfied: py4j in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from hyperopt>=0.2.7->flair) (0.10.9.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=2.2.3->flair) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=2.2.3->flair) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=2.2.3->flair) (10.0.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=2.2.3->flair) (3.0.9)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=2.2.3->flair) (6.0.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (3.1.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch!=1.8,>=1.5.0->flair) (1.12)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch!=1.8,>=1.5.0->flair) (3.1.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\lucas\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.26.0->flair) (0.4.6)\n",
            "Requirement already satisfied: datasets<3.0.0,>=2.0.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformer-smaller-training-vocab>=0.2.1->flair) (2.14.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers[sentencepiece]>=4.18.0->flair) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers[sentencepiece]>=4.18.0->flair) (0.3.1)\n",
            "Requirement already satisfied: protobuf in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers[sentencepiece]>=4.18.0->flair) (4.23.4)\n",
            "Requirement already satisfied: botocore<1.32.0,>=1.31.14 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from boto3->flair) (1.31.14)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from boto3->flair) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from boto3->flair) (0.6.1)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\lucas\\appdata\\roaming\\python\\python39\\site-packages (from ftfy->flair) (0.2.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from botocore<1.32.0,>=1.31.14->boto3->flair) (1.26.16)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (12.0.1)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (0.3.7)\n",
            "Requirement already satisfied: pandas in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (2.0.3)\n",
            "Requirement already satisfied: xxhash in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (3.8.5)\n",
            "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\lucas\\appdata\\roaming\\python\\python39\\site-packages (from importlib-resources>=3.2.0->matplotlib>=2.2.3->flair) (3.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests[socks]->gdown==4.4.0->flair) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests[socks]->gdown==4.4.0->flair) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests[socks]->gdown==4.4.0->flair) (2023.5.7)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers[sentencepiece]>=4.18.0->flair) (0.21.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from beautifulsoup4->gdown==4.4.0->flair) (2.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch!=1.8,>=1.5.0->flair) (2.1.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests[socks]->gdown==4.4.0->flair) (1.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy->torch!=1.8,>=1.5.0->flair) (1.3.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\lucas\\appdata\\roaming\\python\\python39\\site-packages (from accelerate>=0.20.3->transformers[sentencepiece]>=4.18.0->flair) (5.9.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (1.3.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (2023.3)\n"
          ]
        }
      ],
      "source": [
        "pip install flair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rr-57q9TCLc2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldGM4tXJvZ28",
        "outputId": "91c4917e-128a-4d7f-a3fc-18d338a8b496"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-07-28 17:49:01,669 Reading data from .\n",
            "2023-07-28 17:49:01,669 Train: train.txt\n",
            "2023-07-28 17:49:01,669 Dev: dev.txt\n",
            "2023-07-28 17:49:01,670 Test: test.txt\n"
          ]
        }
      ],
      "source": [
        "columns = {0: 'text', 1: 'pos', 2: 'ner'}\n",
        "data_folder = './'\n",
        "\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='train.txt',\n",
        "                              test_file='test.txt',\n",
        "                              dev_file='dev.txt',\n",
        "                              encoding='Latin-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzvpIJuhyyKO",
        "outputId": "e42d67d3-f654-42cd-8c3a-b668535e4f09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 38367\n",
            "Test size: 4795\n",
            "Dev size: 4797\n"
          ]
        }
      ],
      "source": [
        "print(\"Train size: \" + str(len(corpus.train)))\n",
        "print(\"Test size: \" + str(len(corpus.test)))\n",
        "print(\"Dev size: \" + str(len(corpus.dev)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W2qweeDylzN",
        "outputId": "23a43294-6843-4ce7-8c65-ce3c3739a98a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence[24]: \"Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\" → [\"London\"/geo, \"Iraq\"/geo, \"British\"/gpe]\n",
            "Sentence[24]: \"Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\" → [\"Thousands\"/NNS, \"of\"/IN, \"demonstrators\"/NNS, \"have\"/VBP, \"marched\"/VBN, \"through\"/IN, \"London\"/NNP, \"to\"/TO, \"protest\"/VB, \"the\"/DT, \"war\"/NN, \"in\"/IN, \"Iraq\"/NNP, \"and\"/CC, \"demand\"/VB, \"the\"/DT, \"withdrawal\"/NN, \"of\"/IN, \"British\"/JJ, \"troops\"/NNS, \"from\"/IN, \"that\"/DT, \"country\"/NN, \".\"/.]\n"
          ]
        }
      ],
      "source": [
        "print(corpus.train[0].to_tagged_string('ner'))\n",
        "print(corpus.train[0].to_tagged_string('pos'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cshHSnqdBeb7"
      },
      "source": [
        "## Treinando modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Xx943sylBlCW"
      },
      "outputs": [],
      "source": [
        "from flair.embeddings import TransformerWordEmbeddings, WordEmbeddings, FlairEmbeddings, StackedEmbeddings\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyFUXxT7CW4W",
        "outputId": "c39534a4-9498-4e70-b082-68ca08b8967c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-07-28 17:49:20,315 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "38367it [00:00, 62611.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-07-28 17:49:20,934 Dictionary created for label 'ner' with 8 values: geo (seen 29942 times), tim (seen 16305 times), org (seen 16180 times), per (seen 13672 times), gpe (seen 12756 times), art (seen 310 times), eve (seen 244 times), nat (seen 168 times)\n",
            "\n",
            "Labels Dictionary: Dictionary with 8 tags: geo, tim, org, per, gpe, art, eve, nat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "label_type = 'ner' # named entity recognition\n",
        "\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type, add_unk=False)\n",
        "print(\"\\nLabels Dictionary: \" + str(label_dict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjoLYHGfEHub"
      },
      "source": [
        "Modelo NER com transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "082c948b151d41db84502e5d8cbe564a",
            "8b00cc7b3e134c398122bc5c20d130ca",
            "5803c5de764c42b3a46ce50ee464e295",
            "d582fa630b024f9f8e26d9dfa1ecddda",
            "8461fbce88bb43d6a6a24eef9f94b53d",
            "7271be1148444dee80ca3151275cff3f",
            "3a9e11d44cb84bb09ecefcfaacca6c95",
            "76f4f1675eb64b929a7abd5d19a88ca1",
            "ad7a7ca10c04444b9cf6a6e47fdb1d0a",
            "0332d5b5363d419abda76e15c16d887c",
            "ffc46c323ee04732a9d42445b840a833",
            "55066b2e2fe943b5a5ad466df3711e88",
            "b14dffc75c7342ea8349d71ebd7778de",
            "8c2f075c54c949ab99cd2d7d6bb98856",
            "c2da3a28044a465592759377cfda6914",
            "381d1f7c55ed4179a84f8f0787a9f5d7",
            "55fdcac0c7734201ac9a94c7e309d0ce",
            "40bb9b480519416c87865afcc757ede8",
            "29c6f64e1e4c44c58e267f66f829c270",
            "a9f9effceb484e529c0a366701faf932",
            "c21d6b200f134ad79b1a428f26bd312c",
            "1b4c9094a49b4ae68900167ba5570dc7",
            "36af4c3e7a1f47b4b73bfd7ddc4f6d87",
            "6cbfb267e9f74dc0a59d77025883cba0",
            "8683f743d3c148aaabedbb0606b13413",
            "75210c2bc21440859da4c32e4ac2c97c",
            "b814acd83b2946a28fd0cac33cf044eb",
            "36eea14d18454698a61bf4cf8f430b0e",
            "950ed009cca24f0e9f9fcb81d6891fb8",
            "c9ae5a8034e94f9598c92e40e8c0ce4d",
            "34e9d45a701c4f5c895ef2f37adeec0f",
            "93bc826b6fec40ebab361caac76dc258",
            "2d89d01d718d4d438cfbe1eefad9951e",
            "11fac856b21848fbb5e325f83b29aeaa",
            "1f6f066eff0641b8b3f5bf11178cf49b",
            "8eb3f4089dda4b6fa9aff67716729544",
            "99d6ee40a85d4cc59562fb1eb2de8495",
            "81afa739dfee400ca014cf996e7e592a",
            "75478d9964404d7b82bc3f873f9cbeff",
            "609d3c83c61349afaf04abb695eb1b3c",
            "2c1ce96246fb44d39ec2c90d88cfacc7",
            "793a23bef2bc4a23a591292128aa5417",
            "067897f968d74f8483ab551f552bcbb8",
            "83fe33a749bf4d0d84e988ba5ae7415d"
          ]
        },
        "id": "tf86js8RCwgd",
        "outputId": "c24c9bd3-2988-4f86-eb92-8a7d3ebdf16b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-07-28 17:49:52,904 SequenceTagger predicts: Dictionary with 33 tags: O, S-geo, B-geo, E-geo, I-geo, S-tim, B-tim, E-tim, I-tim, S-org, B-org, E-org, I-org, S-per, B-per, E-per, I-per, S-gpe, B-gpe, E-gpe, I-gpe, S-art, B-art, E-art, I-art, S-eve, B-eve, E-eve, I-eve, S-nat, B-nat, E-nat, I-nat\n",
            "2023-07-28 17:49:52,911 ----------------------------------------------------------------------------------------------------\n",
            "2023-07-28 17:49:52,912 Model: \"SequenceTagger(\n",
            "  (embeddings): TransformerWordEmbeddings(\n",
            "    (model): XLMRobertaModel(\n",
            "      (embeddings): XLMRobertaEmbeddings(\n",
            "        (word_embeddings): Embedding(250003, 1024)\n",
            "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
            "        (token_type_embeddings): Embedding(1, 1024)\n",
            "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): XLMRobertaEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0-23): 24 x XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): XLMRobertaPooler(\n",
            "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (linear): Linear(in_features=1024, out_features=33, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2023-07-28 17:49:52,913 ----------------------------------------------------------------------------------------------------\n",
            "2023-07-28 17:49:52,913 Corpus: \"Corpus: 38367 train + 4797 dev + 4795 test sentences\"\n",
            "2023-07-28 17:49:52,914 ----------------------------------------------------------------------------------------------------\n",
            "2023-07-28 17:49:52,914 Parameters:\n",
            "2023-07-28 17:49:52,914  - learning_rate: \"0.000005\"\n",
            "2023-07-28 17:49:52,915  - mini_batch_size: \"4\"\n",
            "2023-07-28 17:49:52,915  - patience: \"3\"\n",
            "2023-07-28 17:49:52,916  - anneal_factor: \"0.5\"\n",
            "2023-07-28 17:49:52,916  - max_epochs: \"10\"\n",
            "2023-07-28 17:49:52,916  - shuffle: \"True\"\n",
            "2023-07-28 17:49:52,917  - train_with_dev: \"False\"\n",
            "2023-07-28 17:49:52,917  - batch_growth_annealing: \"False\"\n",
            "2023-07-28 17:49:52,917 ----------------------------------------------------------------------------------------------------\n",
            "2023-07-28 17:49:52,918 Model training base path: \"resources\\taggers\\sota-ner-flert\"\n",
            "2023-07-28 17:49:52,918 ----------------------------------------------------------------------------------------------------\n",
            "2023-07-28 17:49:52,919 Device: cpu\n",
            "2023-07-28 17:49:52,919 ----------------------------------------------------------------------------------------------------\n",
            "2023-07-28 17:49:52,920 Embeddings storage mode: none\n",
            "2023-07-28 17:49:52,921 ----------------------------------------------------------------------------------------------------\n",
            "2023-07-28 22:18:58,717 epoch 1 - iter 959/9592 - loss 2.77886514 - time (sec): 16145.80 - samples/sec: 5.20 - lr: 0.000000\n",
            "2023-07-28 23:27:22,926 ----------------------------------------------------------------------------------------------------\n",
            "2023-07-28 23:27:22,928 Exiting from training early.\n",
            "2023-07-28 23:27:22,928 Saving model ...\n",
            "2023-07-28 23:27:28,598 Done.\n",
            "2023-07-28 23:27:28,645 ----------------------------------------------------------------------------------------------------\n",
            "2023-07-28 23:27:28,648 Testing using last state of model ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 7/1199 [00:28<1:20:23,  4.05s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 19\u001b[0m\n\u001b[0;32m      8\u001b[0m tagger \u001b[39m=\u001b[39m SequenceTagger(hidden_size\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m,\n\u001b[0;32m      9\u001b[0m                         embeddings\u001b[39m=\u001b[39membeddings,\n\u001b[0;32m     10\u001b[0m                         tag_dictionary\u001b[39m=\u001b[39mlabel_dict,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m                         reproject_embeddings\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     15\u001b[0m                         )\n\u001b[0;32m     17\u001b[0m trainer \u001b[39m=\u001b[39m ModelTrainer(tagger, corpus)\n\u001b[1;32m---> 19\u001b[0m trainer\u001b[39m.\u001b[39;49mfine_tune(\u001b[39m'\u001b[39;49m\u001b[39mresources/taggers/sota-ner-flert\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     20\u001b[0m                   learning_rate\u001b[39m=\u001b[39;49m\u001b[39m5.0e-6\u001b[39;49m,\n\u001b[0;32m     21\u001b[0m                   mini_batch_size\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m,\n\u001b[0;32m     22\u001b[0m                   \u001b[39m#mini_batch_chunk_size=1,\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m                   )\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\flair\\trainers\\trainer.py:985\u001b[0m, in \u001b[0;36mModelTrainer.fine_tune\u001b[1;34m(self, base_path, learning_rate, max_epochs, optimizer, scheduler, warmup_fraction, mini_batch_size, embeddings_storage_mode, use_final_model_for_eval, decoder_lr_factor, **trainer_args)\u001b[0m\n\u001b[0;32m    968\u001b[0m     optimizer \u001b[39m=\u001b[39m optimizer(\n\u001b[0;32m    969\u001b[0m         [\n\u001b[0;32m    970\u001b[0m             {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    978\u001b[0m         ]\n\u001b[0;32m    979\u001b[0m     )\n\u001b[0;32m    980\u001b[0m     log\u001b[39m.\u001b[39minfo(\n\u001b[0;32m    981\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModifying learning rate to \u001b[39m\u001b[39m{\u001b[39;00mlearning_rate\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39mdecoder_lr_factor\u001b[39m}\u001b[39;00m\u001b[39m for the following \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    982\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameters: \u001b[39m\u001b[39m{\u001b[39;00m[name\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mname,\u001b[39m \u001b[39mparam\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mnamed_parameters()\u001b[39m \u001b[39m\u001b[39mif\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39membeddings\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39mnot\u001b[39;00m\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mname]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    983\u001b[0m     )\n\u001b[1;32m--> 985\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain(\n\u001b[0;32m    986\u001b[0m     base_path\u001b[39m=\u001b[39mbase_path,\n\u001b[0;32m    987\u001b[0m     learning_rate\u001b[39m=\u001b[39mlearning_rate,\n\u001b[0;32m    988\u001b[0m     max_epochs\u001b[39m=\u001b[39mmax_epochs,\n\u001b[0;32m    989\u001b[0m     optimizer\u001b[39m=\u001b[39moptimizer,\n\u001b[0;32m    990\u001b[0m     scheduler\u001b[39m=\u001b[39mscheduler,\n\u001b[0;32m    991\u001b[0m     warmup_fraction\u001b[39m=\u001b[39mwarmup_fraction,\n\u001b[0;32m    992\u001b[0m     mini_batch_size\u001b[39m=\u001b[39mmini_batch_size,\n\u001b[0;32m    993\u001b[0m     embeddings_storage_mode\u001b[39m=\u001b[39membeddings_storage_mode,\n\u001b[0;32m    994\u001b[0m     use_final_model_for_eval\u001b[39m=\u001b[39muse_final_model_for_eval,\n\u001b[0;32m    995\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrainer_args,\n\u001b[0;32m    996\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\flair\\trainers\\trainer.py:893\u001b[0m, in \u001b[0;36mModelTrainer.train\u001b[1;34m(self, base_path, learning_rate, mini_batch_size, eval_batch_size, mini_batch_chunk_size, max_epochs, train_with_dev, train_with_test, monitor_train, monitor_test, main_evaluation_metric, scheduler, anneal_factor, patience, min_learning_rate, initial_extra_patience, optimizer, cycle_momentum, warmup_fraction, embeddings_storage_mode, checkpoint, save_final_model, anneal_with_restarts, anneal_with_prestarts, anneal_against_dev_loss, batch_growth_annealing, shuffle, param_selection_mode, write_weights, num_workers, sampler, use_amp, amp_opt_level, eval_on_train_fraction, eval_on_train_shuffle, save_model_each_k_epochs, tensorboard_comment, use_swa, use_final_model_for_eval, gold_label_dictionary_for_eval, exclude_labels, create_file_logs, create_loss_file, epoch, use_tensorboard, tensorboard_log_dir, metrics_for_tensorboard, optimizer_state_dict, scheduler_state_dict, save_optimizer_state, reduce_transformer_vocab, shuffle_first_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[39m# test best model if test data is present\u001b[39;00m\n\u001b[0;32m    892\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcorpus\u001b[39m.\u001b[39mtest \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m train_with_test:\n\u001b[1;32m--> 893\u001b[0m     final_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfinal_test(\n\u001b[0;32m    894\u001b[0m         base_path\u001b[39m=\u001b[39;49mbase_path,\n\u001b[0;32m    895\u001b[0m         eval_mini_batch_size\u001b[39m=\u001b[39;49meval_batch_size,\n\u001b[0;32m    896\u001b[0m         num_workers\u001b[39m=\u001b[39;49mnum_workers,\n\u001b[0;32m    897\u001b[0m         main_evaluation_metric\u001b[39m=\u001b[39;49mmain_evaluation_metric,\n\u001b[0;32m    898\u001b[0m         gold_label_dictionary_for_eval\u001b[39m=\u001b[39;49mgold_label_dictionary_for_eval,\n\u001b[0;32m    899\u001b[0m         exclude_labels\u001b[39m=\u001b[39;49mexclude_labels,\n\u001b[0;32m    900\u001b[0m     )\n\u001b[0;32m    901\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    902\u001b[0m     final_score \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\flair\\trainers\\trainer.py:1020\u001b[0m, in \u001b[0;36mModelTrainer.final_test\u001b[1;34m(self, base_path, eval_mini_batch_size, main_evaluation_metric, num_workers, gold_label_dictionary_for_eval, exclude_labels)\u001b[0m\n\u001b[0;32m   1017\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mTesting using last state of model ...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1019\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcorpus\u001b[39m.\u001b[39mtest\n\u001b[1;32m-> 1020\u001b[0m test_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mevaluate(\n\u001b[0;32m   1021\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcorpus\u001b[39m.\u001b[39;49mtest,\n\u001b[0;32m   1022\u001b[0m     gold_label_type\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mlabel_type,\n\u001b[0;32m   1023\u001b[0m     mini_batch_size\u001b[39m=\u001b[39;49meval_mini_batch_size,\n\u001b[0;32m   1024\u001b[0m     num_workers\u001b[39m=\u001b[39;49mnum_workers,\n\u001b[0;32m   1025\u001b[0m     out_path\u001b[39m=\u001b[39;49mbase_path \u001b[39m/\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mtest.tsv\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1026\u001b[0m     embedding_storage_mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mnone\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1027\u001b[0m     main_evaluation_metric\u001b[39m=\u001b[39;49mmain_evaluation_metric,\n\u001b[0;32m   1028\u001b[0m     gold_label_dictionary\u001b[39m=\u001b[39;49mgold_label_dictionary_for_eval,\n\u001b[0;32m   1029\u001b[0m     exclude_labels\u001b[39m=\u001b[39;49mexclude_labels,\n\u001b[0;32m   1030\u001b[0m     return_loss\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1031\u001b[0m )\n\u001b[0;32m   1033\u001b[0m log\u001b[39m.\u001b[39minfo(test_results\u001b[39m.\u001b[39mlog_line)\n\u001b[0;32m   1034\u001b[0m log\u001b[39m.\u001b[39minfo(test_results\u001b[39m.\u001b[39mdetailed_results)\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\flair\\nn\\model.py:296\u001b[0m, in \u001b[0;36mClassifier.evaluate\u001b[1;34m(self, data_points, gold_label_type, out_path, embedding_storage_mode, mini_batch_size, num_workers, main_evaluation_metric, exclude_labels, gold_label_dictionary, return_loss, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m     datapoint\u001b[39m.\u001b[39mremove_labels(\u001b[39m\"\u001b[39m\u001b[39mpredicted\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    295\u001b[0m \u001b[39m# predict for batch\u001b[39;00m\n\u001b[1;32m--> 296\u001b[0m loss_and_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(\n\u001b[0;32m    297\u001b[0m     batch,\n\u001b[0;32m    298\u001b[0m     embedding_storage_mode\u001b[39m=\u001b[39;49membedding_storage_mode,\n\u001b[0;32m    299\u001b[0m     mini_batch_size\u001b[39m=\u001b[39;49mmini_batch_size,\n\u001b[0;32m    300\u001b[0m     label_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpredicted\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    301\u001b[0m     return_loss\u001b[39m=\u001b[39;49mreturn_loss,\n\u001b[0;32m    302\u001b[0m )\n\u001b[0;32m    304\u001b[0m \u001b[39mif\u001b[39;00m return_loss:\n\u001b[0;32m    305\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(loss_and_count, \u001b[39mtuple\u001b[39m):\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\flair\\models\\sequence_tagger_model.py:483\u001b[0m, in \u001b[0;36mSequenceTagger.predict\u001b[1;34m(self, sentences, mini_batch_size, return_probabilities_for_all_classes, verbose, label_name, return_loss, embedding_storage_mode, force_token_predictions)\u001b[0m\n\u001b[0;32m    480\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[39m# get features from forward propagation\u001b[39;00m\n\u001b[1;32m--> 483\u001b[0m sentence_tensor, lengths \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_tensors(batch)\n\u001b[0;32m    484\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(sentence_tensor, lengths)\n\u001b[0;32m    486\u001b[0m \u001b[39m# remove previously predicted labels of this type\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\flair\\models\\sequence_tagger_model.py:287\u001b[0m, in \u001b[0;36mSequenceTagger._prepare_tensors\u001b[1;34m(self, data_points)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    286\u001b[0m     sentences \u001b[39m=\u001b[39m data_points\n\u001b[1;32m--> 287\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings\u001b[39m.\u001b[39;49membed(sentences)\n\u001b[0;32m    289\u001b[0m \u001b[39m# make a zero-padded tensor for the whole sentence\u001b[39;00m\n\u001b[0;32m    290\u001b[0m lengths, sentence_tensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_padded_tensor_for_batch(sentences)\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\flair\\embeddings\\base.py:49\u001b[0m, in \u001b[0;36mEmbeddings.embed\u001b[1;34m(self, data_points)\u001b[0m\n\u001b[0;32m     46\u001b[0m     data_points \u001b[39m=\u001b[39m [data_points]\n\u001b[0;32m     48\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_everything_embedded(data_points):\n\u001b[1;32m---> 49\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_embeddings_internal(data_points)\n\u001b[0;32m     51\u001b[0m \u001b[39mreturn\u001b[39;00m data_points\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\flair\\embeddings\\transformer.py:662\u001b[0m, in \u001b[0;36mTransformerBaseEmbeddings._add_embeddings_internal\u001b[1;34m(self, sentences)\u001b[0m\n\u001b[0;32m    660\u001b[0m gradient_context \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39menable_grad() \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfine_tune \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining) \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad()\n\u001b[0;32m    661\u001b[0m \u001b[39mwith\u001b[39;00m gradient_context:\n\u001b[1;32m--> 662\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_tensors(tensors)\n\u001b[0;32m    664\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdocument_embedding:\n\u001b[0;32m    665\u001b[0m     document_embedding \u001b[39m=\u001b[39m embeddings[\u001b[39m\"\u001b[39m\u001b[39mdocument_embeddings\u001b[39m\u001b[39m\"\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\flair\\embeddings\\transformer.py:1319\u001b[0m, in \u001b[0;36mTransformerEmbeddings._forward_tensors\u001b[1;34m(self, tensors)\u001b[0m\n\u001b[0;32m   1318\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_tensors\u001b[39m(\u001b[39mself\u001b[39m, tensors) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m-> 1319\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtensors)\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\flair\\embeddings\\transformer.py:1223\u001b[0m, in \u001b[0;36mTransformerEmbeddings.forward\u001b[1;34m(self, input_ids, sub_token_lengths, token_lengths, attention_mask, overflow_to_sample_mapping, word_ids, langs, bbox, pixel_values)\u001b[0m\n\u001b[0;32m   1221\u001b[0m \u001b[39mif\u001b[39;00m pixel_values \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1222\u001b[0m     model_kwargs[\u001b[39m\"\u001b[39m\u001b[39mpixel_values\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pixel_values\n\u001b[1;32m-> 1223\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m   1224\u001b[0m \u001b[39m# make the tuple a tensor; makes working with it easier.\u001b[39;00m\n\u001b[0;32m   1225\u001b[0m hidden_states \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(hidden_states)\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:846\u001b[0m, in \u001b[0;36mXLMRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    837\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    839\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m    840\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m    841\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    844\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    845\u001b[0m )\n\u001b[1;32m--> 846\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m    847\u001b[0m     embedding_output,\n\u001b[0;32m    848\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m    849\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    850\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m    851\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m    852\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m    853\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    854\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    855\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    856\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    857\u001b[0m )\n\u001b[0;32m    858\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    859\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:530\u001b[0m, in \u001b[0;36mXLMRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    521\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    522\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    523\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    527\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    528\u001b[0m     )\n\u001b[0;32m    529\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 530\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    531\u001b[0m         hidden_states,\n\u001b[0;32m    532\u001b[0m         attention_mask,\n\u001b[0;32m    533\u001b[0m         layer_head_mask,\n\u001b[0;32m    534\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    535\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    536\u001b[0m         past_key_value,\n\u001b[0;32m    537\u001b[0m         output_attentions,\n\u001b[0;32m    538\u001b[0m     )\n\u001b[0;32m    540\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    541\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:414\u001b[0m, in \u001b[0;36mXLMRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    403\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    404\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    411\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m    412\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    413\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[0;32m    415\u001b[0m         hidden_states,\n\u001b[0;32m    416\u001b[0m         attention_mask,\n\u001b[0;32m    417\u001b[0m         head_mask,\n\u001b[0;32m    418\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    419\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[0;32m    420\u001b[0m     )\n\u001b[0;32m    421\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    423\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:341\u001b[0m, in \u001b[0;36mXLMRobertaAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    332\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    333\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    339\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    340\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m--> 341\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[0;32m    342\u001b[0m         hidden_states,\n\u001b[0;32m    343\u001b[0m         attention_mask,\n\u001b[0;32m    344\u001b[0m         head_mask,\n\u001b[0;32m    345\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    346\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    347\u001b[0m         past_key_value,\n\u001b[0;32m    348\u001b[0m         output_attentions,\n\u001b[0;32m    349\u001b[0m     )\n\u001b[0;32m    350\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[0;32m    351\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:220\u001b[0m, in \u001b[0;36mXLMRobertaSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    218\u001b[0m     value_layer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([past_key_value[\u001b[39m1\u001b[39m], value_layer], dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m    219\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 220\u001b[0m     key_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey(hidden_states))\n\u001b[0;32m    221\u001b[0m     value_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue(hidden_states))\n\u001b[0;32m    223\u001b[0m query_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(mixed_query_layer)\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "embeddings = TransformerWordEmbeddings(model='xlm-roberta-large',\n",
        "                                       layers=\"-1\",\n",
        "                                       subtoken_pooling=\"first\",\n",
        "                                       fine_tune=True,\n",
        "                                       use_context=True,\n",
        "                                       )\n",
        "\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type='ner',\n",
        "                        use_crf=False,\n",
        "                        use_rnn=False,\n",
        "                        reproject_embeddings=False,\n",
        "                        )\n",
        "\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "trainer.fine_tune('resources/taggers/sota-ner-flert',\n",
        "                  learning_rate=5.0e-6,\n",
        "                  mini_batch_size=4,\n",
        "                  #mini_batch_chunk_size=1,\n",
        "                  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSB5ktEkEMYd"
      },
      "source": [
        "Modelo NER com Flair embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOkSNPvgEBl9"
      },
      "outputs": [],
      "source": [
        "embedding_types = [\n",
        "    WordEmbeddings('glove'),\n",
        "    FlairEmbeddings('news-forward'),\n",
        "    FlairEmbeddings('news-backward'),\n",
        "]\n",
        "\n",
        "embeddings = StackedEmbeddings(embeddings=embedding_types)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0332d5b5363d419abda76e15c16d887c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "067897f968d74f8483ab551f552bcbb8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "082c948b151d41db84502e5d8cbe564a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b00cc7b3e134c398122bc5c20d130ca",
              "IPY_MODEL_5803c5de764c42b3a46ce50ee464e295",
              "IPY_MODEL_d582fa630b024f9f8e26d9dfa1ecddda"
            ],
            "layout": "IPY_MODEL_8461fbce88bb43d6a6a24eef9f94b53d"
          }
        },
        "11fac856b21848fbb5e325f83b29aeaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f6f066eff0641b8b3f5bf11178cf49b",
              "IPY_MODEL_8eb3f4089dda4b6fa9aff67716729544",
              "IPY_MODEL_99d6ee40a85d4cc59562fb1eb2de8495"
            ],
            "layout": "IPY_MODEL_81afa739dfee400ca014cf996e7e592a"
          }
        },
        "1b4c9094a49b4ae68900167ba5570dc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f6f066eff0641b8b3f5bf11178cf49b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75478d9964404d7b82bc3f873f9cbeff",
            "placeholder": "​",
            "style": "IPY_MODEL_609d3c83c61349afaf04abb695eb1b3c",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "29c6f64e1e4c44c58e267f66f829c270": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c1ce96246fb44d39ec2c90d88cfacc7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d89d01d718d4d438cfbe1eefad9951e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34e9d45a701c4f5c895ef2f37adeec0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36af4c3e7a1f47b4b73bfd7ddc4f6d87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6cbfb267e9f74dc0a59d77025883cba0",
              "IPY_MODEL_8683f743d3c148aaabedbb0606b13413",
              "IPY_MODEL_75210c2bc21440859da4c32e4ac2c97c"
            ],
            "layout": "IPY_MODEL_b814acd83b2946a28fd0cac33cf044eb"
          }
        },
        "36eea14d18454698a61bf4cf8f430b0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "381d1f7c55ed4179a84f8f0787a9f5d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a9e11d44cb84bb09ecefcfaacca6c95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40bb9b480519416c87865afcc757ede8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55066b2e2fe943b5a5ad466df3711e88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b14dffc75c7342ea8349d71ebd7778de",
              "IPY_MODEL_8c2f075c54c949ab99cd2d7d6bb98856",
              "IPY_MODEL_c2da3a28044a465592759377cfda6914"
            ],
            "layout": "IPY_MODEL_381d1f7c55ed4179a84f8f0787a9f5d7"
          }
        },
        "55fdcac0c7734201ac9a94c7e309d0ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5803c5de764c42b3a46ce50ee464e295": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76f4f1675eb64b929a7abd5d19a88ca1",
            "max": 616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad7a7ca10c04444b9cf6a6e47fdb1d0a",
            "value": 616
          }
        },
        "609d3c83c61349afaf04abb695eb1b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cbfb267e9f74dc0a59d77025883cba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36eea14d18454698a61bf4cf8f430b0e",
            "placeholder": "​",
            "style": "IPY_MODEL_950ed009cca24f0e9f9fcb81d6891fb8",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "7271be1148444dee80ca3151275cff3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75210c2bc21440859da4c32e4ac2c97c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93bc826b6fec40ebab361caac76dc258",
            "placeholder": "​",
            "style": "IPY_MODEL_2d89d01d718d4d438cfbe1eefad9951e",
            "value": " 9.10M/9.10M [00:00&lt;00:00, 30.7MB/s]"
          }
        },
        "75478d9964404d7b82bc3f873f9cbeff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76f4f1675eb64b929a7abd5d19a88ca1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "793a23bef2bc4a23a591292128aa5417": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81afa739dfee400ca014cf996e7e592a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83fe33a749bf4d0d84e988ba5ae7415d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8461fbce88bb43d6a6a24eef9f94b53d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8683f743d3c148aaabedbb0606b13413": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9ae5a8034e94f9598c92e40e8c0ce4d",
            "max": 9096718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34e9d45a701c4f5c895ef2f37adeec0f",
            "value": 9096718
          }
        },
        "8b00cc7b3e134c398122bc5c20d130ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7271be1148444dee80ca3151275cff3f",
            "placeholder": "​",
            "style": "IPY_MODEL_3a9e11d44cb84bb09ecefcfaacca6c95",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "8c2f075c54c949ab99cd2d7d6bb98856": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29c6f64e1e4c44c58e267f66f829c270",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9f9effceb484e529c0a366701faf932",
            "value": 5069051
          }
        },
        "8eb3f4089dda4b6fa9aff67716729544": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c1ce96246fb44d39ec2c90d88cfacc7",
            "max": 2244817354,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_793a23bef2bc4a23a591292128aa5417",
            "value": 2244817354
          }
        },
        "93bc826b6fec40ebab361caac76dc258": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "950ed009cca24f0e9f9fcb81d6891fb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99d6ee40a85d4cc59562fb1eb2de8495": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_067897f968d74f8483ab551f552bcbb8",
            "placeholder": "​",
            "style": "IPY_MODEL_83fe33a749bf4d0d84e988ba5ae7415d",
            "value": " 2.24G/2.24G [00:19&lt;00:00, 174MB/s]"
          }
        },
        "a9f9effceb484e529c0a366701faf932": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad7a7ca10c04444b9cf6a6e47fdb1d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b14dffc75c7342ea8349d71ebd7778de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55fdcac0c7734201ac9a94c7e309d0ce",
            "placeholder": "​",
            "style": "IPY_MODEL_40bb9b480519416c87865afcc757ede8",
            "value": "Downloading (…)tencepiece.bpe.model: 100%"
          }
        },
        "b814acd83b2946a28fd0cac33cf044eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c21d6b200f134ad79b1a428f26bd312c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2da3a28044a465592759377cfda6914": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c21d6b200f134ad79b1a428f26bd312c",
            "placeholder": "​",
            "style": "IPY_MODEL_1b4c9094a49b4ae68900167ba5570dc7",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 30.6MB/s]"
          }
        },
        "c9ae5a8034e94f9598c92e40e8c0ce4d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d582fa630b024f9f8e26d9dfa1ecddda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0332d5b5363d419abda76e15c16d887c",
            "placeholder": "​",
            "style": "IPY_MODEL_ffc46c323ee04732a9d42445b840a833",
            "value": " 616/616 [00:00&lt;00:00, 38.9kB/s]"
          }
        },
        "ffc46c323ee04732a9d42445b840a833": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
